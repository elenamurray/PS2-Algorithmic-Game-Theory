{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 1: Computational Approach\n",
    "\n",
    "Try coding up your own simulation of a two-player iterated Prisoner’s Dilemma. Feel free to\n",
    "use Python or R — whichever you prefer. This question is open-ended, but your work should\n",
    "contain some of the following elements:\n",
    "\n",
    "- Try a few strategies that we learned against each other. Some examples you might consider\n",
    "include: tit-for-tat, grim trigger, intermediate punishment strategies, always cooperate,\n",
    "always defect, probabilistic strategies.\n",
    "- Produce some informative plots or summary statistics about the outcomes of your simulation. (You can draw on the plots from papers we’ve read for inspiration.) Some information\n",
    "you might convey includes: which strategies get the highest total payoffs (against which?)?\n",
    "When can cooperation be sustained?\n",
    "- Be sure to reproduce your payoff matrix and all other key decisions you made in your\n",
    "write-up. Think carefully about the number of repetitions of the game you want to do,\n",
    "and why.\n",
    "- If you’d rather experiment with an existing approach rather than writing your own code, feel\n",
    "free to play around with the axelrod Python library: https://github.com/Axelrod-Python/\n",
    "Axelrod. This has built-in tools to create head-to-head matches, tournaments over multiple\n",
    "strategies, and visualizations.\n",
    "\n",
    "Optional extensions:\n",
    "- Incorporate discounting of future utilities\n",
    "- Incorporate some sort of learning or adaptation (for instance, if you want to play around\n",
    "with reinforcement learning, see: https://github.com/Axelrod-Python/axelrod-dojo)\n",
    "Briefly discuss your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "243 players available\n",
      "██████████\n",
      "█ █ █ █ █ \n"
     ]
    }
   ],
   "source": [
    "#Try using Axelrod\n",
    "import axelrod as axl\n",
    "\n",
    "#Check for player types\n",
    "players_list = axl.strategies\n",
    "print(len(players_list), \"players available\")\n",
    "\n",
    "#Example\n",
    "players_ex = [axl.Cooperator(), axl.Alternator()]\n",
    "\n",
    "match = axl.Match(players = players_ex, turns=10)\n",
    "\n",
    "match.play()\n",
    "print(match.sparklines())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(np.int64(3), np.int64(3)),\n",
       " (np.int64(3), np.int64(3)),\n",
       " (np.int64(3), np.int64(3)),\n",
       " (np.int64(3), np.int64(3)),\n",
       " (np.int64(3), np.int64(3))]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Code to get match results\n",
    "\n",
    "match.scores()\n",
    "\n",
    "match.final_score()\n",
    "\n",
    "match.final_score_per_turn()\n",
    "\n",
    "match.winner()\n",
    "\n",
    "match.cooperation()  # The count of cooperations\n",
    "\n",
    "match.normalised_cooperation()  # The count of cooperations per turn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strategies covered in class to test:\n",
    "\n",
    "- Grim trigger\n",
    "- Tit-for-Tat\n",
    "- Intermediate punishment strategies\n",
    "    - Similar to grim trigger: k-Grim Trigger\n",
    "        - Cooperate until your opponent defects. If\n",
    "    your opponent defects, do not cooperate for the next k periods but\n",
    "    then return to cooperation; if you defect, do not cooperate for the\n",
    "    next k periods but then return to cooperation. Once you have\n",
    "    returned to cooperation, cooperate until a defection occurs.\n",
    "    - Similar to tit-for-tat: \n",
    "        - Cooperate until your opponent defects. If your\n",
    "    opponent defects, do not cooperate for k periods. If she cooperates\n",
    "    in any of the k periods, return to cooperation, ending the\n",
    "    punishment phase. If she fails to cooperate in any period of the\n",
    "    punishment phase, then the punishment phase starts over i.e. don’t\n",
    "    cooperate for k more periods. If your own failure to cooperate\n",
    "    caused the punishment phase then cooperate during the punishment\n",
    "    phase.\n",
    "- Always cooperate\n",
    "- Always defect\n",
    "- Probabilistic stragies (ie. 0.7 chance of cooperation)\n",
    "\n",
    "\n",
    "\n",
    "Things to vary:\n",
    "\n",
    "- Finite vs infinite games\n",
    "\n",
    "\n",
    "For finite games:\n",
    "\n",
    "If the stage game G has a unique Nash equilibrium then, for any\n",
    "finite T , the repeated game G (T ) has a unique subgame-perfect\n",
    "outcome: the Nash equilibrium of G is played in every stage.\n",
    "\n",
    "\n",
    "For infinite games:\n",
    "\n",
    "In the infinitely repeated game G (∞,δ), each subgame beginning\n",
    "at stage t + 1 is identical to the original game G (∞,δ). As in\n",
    "the finite-horizon case, there are as many subgames beginning at\n",
    "stage t + 1 of G (∞,δ) as there are possible histories of play\n",
    "through stage t.\n",
    "\n",
    "A Nash equilibrium is subgame-perfect if the players’ strategies\n",
    "constitute a Nash equilibrium in every subgame.\n",
    "\n",
    "- simulate by using δ discount factor - and a repeated game that ends after a random number of repitions. \n",
    "\n",
    "Consider also:\n",
    "- discount rates -> for infinitely repeated games\n",
    "- The Folk Theorem:\n",
    "    - For every feasible and individually rational payoﬀ vector v there is\n",
    "a vector of discount rates δ0 (i.e. one δ0 for each player) such\n",
    "i\n",
    "that the payoﬀ vector v occurs in a Nash equilibrium of the\n",
    "repeated game if δi ≥ δ0 for all i.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example visualisation: https://www.nature.com/articles/s41562-025-02172-y/figures/3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ps2_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
